{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "cpSzCe70pl2B"
   },
   "source": [
    "# New Orleans Dataset\n",
    "\n",
    "Mileva Van Tuyl\n",
    "Funing Yang\n",
    "Daphka Alius\n",
    "Jane Yang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "executionInfo": {
     "elapsed": 572,
     "status": "error",
     "timestamp": 1559654470524,
     "user": {
      "displayName": "Jane Yang",
      "photoUrl": "https://lh5.googleusercontent.com/--JQVDEyswSE/AAAAAAAAAAI/AAAAAAAAAAk/spXCTRt9jik/s64/photo.jpg",
      "userId": "10773794944574800466"
     },
     "user_tz": 240
    },
    "id": "NQ9wDNuipl2C",
    "outputId": "6c24b236-a618-41c7-9b81-ffac19791860"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "from difflib import get_close_matches\n",
    "import pandas as pd\n",
    "import GetOldTweets3 as got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "v3O0YsLzpl2F"
   },
   "outputs": [],
   "source": [
    "tweets = csv.reader(open('/Users/yyang5/Downloads/CredLab_week1/ira_tweets_csv_hashed.csv',encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "_pnwL2Cepl2H"
   },
   "outputs": [],
   "source": [
    "def getFakeTweets(newsName):\n",
    "    nola_clean = []\n",
    "    for tweet in tweets:\n",
    "        if tweet[3] == newsName: \n",
    "            nola_clean.append(tweet)\n",
    "        #print(tweet[12])\n",
    "    with open(newsName+'.txt', 'w') as outfile:\n",
    "        json.dump(nola_clean,outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "Hn7VD0u-pl2I"
   },
   "outputs": [],
   "source": [
    "fake_news_accounts = [\n",
    "#'ElPasoTopNews',\n",
    "#'DailySanJose',\n",
    "#'ChicagoDailyNew',\n",
    "#'DailySanFran',\n",
    "#'DetroitDailyNew',\n",
    "#'TodayCincinnati',\n",
    "'MinneapolisON',\n",
    "'KansasDailyNews',\n",
    "'TodayBostonMA',\n",
    "'TodayPittsburgh',\n",
    "'Seattle_Post',\n",
    "'PhiladelphiaON',\n",
    "'DailyLosAngeles',\n",
    "'HoustonTopNews',\n",
    "'DailySanDiego',\n",
    "'DallasTopNews',\n",
    "'WashingtOnline',\n",
    "'TodayNYCity',\n",
    "'OnlineCleveland',\n",
    "'SanAntoTopNews',\n",
    "'PhoenixDailyNew',\n",
    "'TodayMiami',\n",
    "'Atlanta_Online',\n",
    "'Baltimore0nline',\n",
    "'OaklandOnline',\n",
    "'StLouisOnline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "2IFeVv5Zpl2L",
    "outputId": "66cbfa90-7c30-4fa9-b0c6-373716ad0592"
   },
   "outputs": [],
   "source": [
    "for account in fake_news_accounts:\n",
    "    try:\n",
    "        getFakeTweets(account)\n",
    "    except IndexError:\n",
    "        print(account)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news_obj = []\n",
    "f_start_date =[]\n",
    "f_end_date =[]\n",
    "\n",
    "\n",
    "\n",
    "with open(newsName+'.txt','r') as json_file:\n",
    "    news_obj.append(json.load(json_file))\n",
    "    news_obj[-1].sort(key = lambda aList: aList[13])\n",
    "    f_start_date.append(news_obj[-1][0][13])\n",
    "    f_end_date.append(news_obj[-1][-1][13])\n",
    "\n",
    "    \n",
    "for url in news_obj[-1] \n",
    "    \n",
    "\n",
    "for ftweet in nola_clean:   \n",
    "    if 'http://' or 'https://' in ftweet[12]:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "Vwv9tHl2pl2O",
    "outputId": "80e79e11-a7c9-4396-9df9-11ab065ad1a4"
   },
   "outputs": [],
   "source": [
    "realTweetsList=[]\n",
    "#'2014-09-15', '2014-09-30', '2014-10-15', '2014-10-31','2014-11-15', '2014-11-30', '2014-12-15', '2014-12-31','2015-01-15', '2015-01-31', '2015-02-15', '2015-02-28','2015-03-15', '2015-03-31', '2015-04-15', '2015-04-30','2015-05-15', '2015-05-31', '2015-06-15',\n",
    "#dates= [ '2015-06-30',\n",
    "          #     '2015-07-15', '2015-07-31', '2015-08-15', '2015-08-31',\n",
    "          #     '2015-09-15', '2015-09-30', '2015-10-15', '2015-10-31',\n",
    "          #     '2015-11-15', '2015-11-30', '2015-12-15', '2015-12-31',\n",
    "          #    '2016-01-15']\n",
    "\n",
    "\n",
    "for i in range(len(dates)-1):\n",
    "    realTweets=got.manager.TweetCriteria().setUsername('NOLAnews').setSince(dates[i]).setUntil(dates[i+1])\n",
    "    tweet = got.manager.TweetManager.getTweets(realTweets)[::]\n",
    "    #for item in tweet:\n",
    "        #realTweetsList.append(item.text)\n",
    "    realTweetsList=[(str(item.date),item.id,item.username,item.text,item.hashtags) for item in tweet]\n",
    "    with open(str(dates[i])+'.txt','w') as outfile:\n",
    "        json.dump(realTweetsList,outfile)\n",
    "    realTweetsList =[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(len(realTweetsList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "H_25aNvOpl2Q",
    "outputId": "47371adf-84ab-4e47-e4c1-4ebf2e0d8e7e"
   },
   "outputs": [],
   "source": [
    "# Collect the tweets for the fake NOLA\n",
    "\n",
    "#tweets = csv.reader(open('/Users/yyang5/Downloads/CredLab_week1/ira_tweets_csv_hashed.csv',encoding='utf-8'))\n",
    "#fakeTweetsList=[]\n",
    "#for tweet in tweets:\n",
    "#    fakeTweetsList.append(tweet[12])\n",
    "#print(fakeTweetsList[0])\n",
    "with open('real_tweets.txt','r') as json_file:\n",
    "    real_tweets_obj = json.load(json_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "NnAzCaP9pl2T",
    "outputId": "cdd074f0-7e30-4cea-b889-486192241a62"
   },
   "outputs": [],
   "source": [
    "# How many tweets per day for each (old and fake)\n",
    "\n",
    "# Use the two lists of tweets both sorted by dates: one of fake tweets, one of real tweets\n",
    "# Use len to get how many elements of the list (total tweets)\n",
    "# Get the first and the last element of the dates of both lists\n",
    "# Subtract the latest date and the newest date to get how many days in total\n",
    "# Divide the total dates by the total tweets\n",
    "\n",
    "# suppose we have the two lists: fakeTweetsList, realTweetsList\n",
    "numFakeTweet=len(nola_clean)\n",
    "numRealTweet=len(realTweetsList)\n",
    "\n",
    "# newest/oldest date for fakeTweetsList\n",
    "\n",
    "\n",
    "fakeStart = datetime.datetime(2014,12,27)\n",
    "fakeEnd = datetime.datetime(2017,8,8)\n",
    "fake_diff = abs((fakeEnd-fakeStart).days)\n",
    "\n",
    "realStart= datetime.datetime(2014,9,1)\n",
    "realEnd = datetime.datetime(2017,8,8) \n",
    "real_diff = abs((realEnd-realStart).days)\n",
    "print(\"fake:\" + str(fake_diff)+\" days\")\n",
    "print(\"real:\" +str(real_diff)+\" days\")#datetime delta\n",
    "\n",
    "\n",
    "avg_ftw_per_day = numFakeTweet/fake_diff\n",
    "avg_rtw_per_day = numRealTweet/real_diff\n",
    "\n",
    "print(\"average fake tweets per day: \"+ str(avg_ftw_per_day))\n",
    "print(\"average real tweets per day: \"+ str(avg_rtw_per_day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "type(realEnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "KsvdhIR1pl2W",
    "outputId": "6991fede-2ba8-438b-b3bd-4183f9193b96"
   },
   "outputs": [],
   "source": [
    "# How often are they tweeting with URLs/ no URLs\n",
    "counterFURLs=0\n",
    "counterRURLs=0\n",
    "\n",
    "numFakeTweets=len(nola_clean)\n",
    "numRealTweets=len(realTweetsList)\n",
    "for ftweet in nola_clean:   \n",
    "    if 'http://' or 'https://' in ftweet[12]:\n",
    "        counterFURLs+=1\n",
    "for rtweet in realTweetsList:   \n",
    "    if 'http://' or 'https://' in rtweet:\n",
    "        counterRURLs+=1\n",
    "\n",
    "counterFNoURLs=numFakeTweets-counterFURLs\n",
    "counterRNoURLs=numRealTweets-counterRURLs\n",
    "print(\"# fake tweets with:\" + str(counterFURLs)+ \";with no URLs:\"+str(counterFNoURLs))\n",
    "print(\"# real tweets with no URLs:\"+ str(counterRURLs)+ \";with no URLs:\" + str(counterRNoURLs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "QiwLnVwipl2Y",
    "outputId": "c4da81aa-6269-44c3-cdd4-2bfc33cbe548"
   },
   "outputs": [],
   "source": [
    "# Identify close matches of strings\n",
    "\n",
    "import difflib\n",
    "from difflib import get_close_matches\n",
    "\n",
    "#help(get_close_matches)\n",
    "\n",
    "for ritem in realTweetsList:\n",
    "    get_close_matches(ritem,nola_clean,cutoff=0.6)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "VdpaVxZspl2a"
   },
   "outputs": [],
   "source": [
    "import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "project1 broken code notebook.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
